---
title: "The Factors of Happiness"
author: "Andie Donovan"
date: "6/14/2017"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, cache=TRUE, 
                      fig.width=6, fig.height=5,
                      fig.align='center')
indent1 = '    '
indent2 = '        '
indent3 = '            '

#install.packages('ROCR')
#install.packages('randomForest')
#install.packages('corrplot')
#install.packages('matrixStats')
library(ggplot2) # Data visualization
library(randomForest) #randomForest, treesize
library(dplyr) #filter, group_by, mutate, summarise, etc. 
library(tree) #decision tree
library(class) #knn
library(rpart) #rpart, printcp, etc. for decision trees
library(matrixStats) #column medians
library(ROCR) #ROCR curves
library(corrplot)
```
*Abstract*

The purpose of this project is to investigate the effects of six socio-economic and economic variables on happiness within a country. I will use decision tree and logistic regression classification algorithms with the aim of producing a model that efficiently and accurately predicts whether or not a country will be classified as "happy" based on the given explanatory variables. 

*Introduction:*

In the presence of growing backlash against GDP as the sole indicator of economic progress within a country, world leaders have begun utilizing alternative socio-economic factors as indicators of the progress of living standards within a country. One example of such indicators is percieved life satisfaction and emotional well being; or, more simply stated, happiness. In order to better understand how certain economic and social factors contribute to a population's perceived level of happiness; I conducted statistical analysis of the 2016 Updated World Happiness Report data using R software.  

For the data I used an abridged version of the 2016 Updated World Happiness Report data, which was published by the UN's Sustainable Development Solutions Network (SDSN) on Kaggle for public use. The data set included 156 countries and 13 columns: Happiness Rank, Happiness Score, Lower Confidence Interval, Upper Confidence Interval, Economy/ GDP per capita, Family, Health Life Expectancy, Freedom, Trust/ Government Corruption, Generosity, and Dystopia. I decided on utilizing six attributes of interest (GDP, Family, Health, Freedom, Trust, and Generosity) when creating my classification models. 

*Main Report:*

The World Happiness Report used survey answers from the Gallup World Poll asking between 2000-3000 individuals from over 150 countries to evaluate different aspects of their lives and countries and to rate their happiness on a scale of 1-10. The report isolated six major factors as the most significant determinants of happiness and/or misery: GDP per capita, family and social support, healthy life expectancy, freedom to make life choices, generosity, and trust of government institutions and then assigned each country a score based on its deviation from the scores of Dystopia, a hypothetical country that adopts the lowest world scores for each category. In this sense Dystopia serves as a baseline for comparison and allows for easy scaling of the data. 


*Reading the Data File and Pre-Processing:*

After assigning the data to the variable "Happiness", I first checked to see if there was missing or inaccurate values. Because this was an abridged version of the data (the raw data was unavailable to the public), the data set was fairly clean and did not appear to contain any missing or incorrect values. 

```{r}
Happiness <- read.table('/Users/andiedonovan/Desktop/Happiness_New.txt',header=T,dec='.',sep=",", stringsAsFactors = T)
#View(Happiness)
```


```{r, results='hide'}
is.na(Happiness) 
```
It appears that there are no missing values. 

*Preprocessing the data*:

```{r}
head(Happiness) #Lets take a look at what the data set looks like
str(Happiness) # How many observations, variables, variable class types, levels, etc.
summary(Happiness) #Stats for all of the variables
```

Besides the country names and their corresponding region, all of the variables were numeric. The Happiness Score ranged from 1 to 10, with 1 being the lowest and 10 being the highest/ happiest. The upper and lower confidence interval variables express the 95% confidence interval for that score due to random sampling. Since the sample includes between 2000-3000 individuals, we can assume the distribution is fairly normal. 

The 6 main factors that I investigated: GDP, Family, Health, Freedom, Trust, and Generosity ranged from 0-1, again with 0 being the worst and 1 being the best. I decided that for the majority of my analysis I would only need these six factors and a response variable reflecting the happiness of the country so I removed the unnecessary columns and created a new binary variable called "Happy"" which assigns countries a value of 1 if their Happiness Score was above the world median of 5.314 and 0 if it was equal to or below the median. I put these six variables and "Happy"" into a new data frame called "happy.new". I then scaled the numerical variables of the data frame and labeled it "happy.s"

```{r}
colnames(Happiness)<-c("Country","Region", "Rank","Score", "LCI","UCI", "GDP","Family", "Health", "Freedom", "Trust", "Generosity", "Dystopia") #Renaming the columns/ variables

Happiness = Happiness %>% mutate(Happy=as.factor(ifelse(Score <= median(Score), "0", "1"))) #Creating a new binary variable "Happy" based on Happiness score of each country

new.happy = Happiness %>% 
  mutate(Happy=as.factor(ifelse(Score <= median(Score), "No", "Yes"))) %>% 
  select(-Country, -Region, -Rank, -Score, -LCI, -UCI, -Dystopia) #Creating a new data set with only the Happy variable and the 6 predictor attributes

scaled<-scale(new.happy[,1:6]) #Scaled predictor variable, makes comparison easier
happy.s<-cbind(scaled, new.happy$Happy) #add Happy variable back 
happy.s<-as.data.frame(happy.s)
happy.s= happy.s %>% mutate(Happy=as.factor(ifelse(V7<2, "0", "1"))) 
happy.s=happy.s[,-7]
```

I did not include the country associated with each observed set of attributes because my aim was to determine a general model for predicting happiness, independent of specific country factors. I also chose not to include region because it unlikely that geographic location directly influence happiness. It is possible, however, that geographic location and assiciated cultural 

The data set also includes the variable "dystopia residual" which combines the lowest scores for each variable out of all the countries and assigns it to a hypothetical country called "Dystopia". However, I did not include this in my model since I was not interested in a comparison between countries. 

*Exploratory Analysis and Basic Data Visualization:*

*Correlation Plot*

To explore the relationship between the variables, I created a correlation plot using standard Pearson distance. 
```{r}
cor.happy<-cor(new.happy[,1:6], use="complete", method="pearson") 
corrplot(cor.happy)
```

We see that GDP and Health have the highest correlation while GDP and Generosity have a slightly negative correlation. While the positive relationship between health/life expectancy and income per capita makes sense (higher income means a stable food supply and more money to spend on health care), the relationship between generosity and GDP is counter-intuitive and indicates that people living in wealthier countries may be less inclined to donate to charitable causes. Generosity also has low correlation with Family and Health. 

*Means and Medians:*

```{r}
new.happy.numeric<-new.happy[,1:6]
new.happy.numeric<-as.matrix(new.happy.numeric)
Medians<-colMedians(new.happy.numeric, na.rm=FALSE)
Means<-colMeans(new.happy.numeric, na.rm = FALSE)
comp<-cbind(Medians,Means)
comp
min(new.happy$Family)
max(new.happy$Family)
```

I produced a table of the means and medians to compare central tendencies and search for clues of skewed distributions. From this table, it is very easy to see that means are very close to the medians for all of the variables, giving no indication of skew. 

*Boxplots:*

To further illustrate the distributions I plotted the boxplots of my main six attributes for each level of the response variable: "happy" (assigned a value of 1) or "unhappy" (value of 0). I found that for countries labeled as unhappy, the distributions for health, GDP, Family, and Freedom appeared to be fairly symmetric. Conversely, the distributions for Generosity and Trust seemed skewed to the right. I hypothesized that this could be due to large differences in available income and government transparency and accountability across countries with lower population satisfaction. Unsurprisingly, the scores were lower for every variable for unhappy countries when compared to those of happy countries. The discrepencies are most noticable in the boxplots for GDP, Family, and Health. Interestingly, the plots for the variable Generosity are almost identical accrross happy and unhappy countries, indicating that perhaps Generosity is either a fairly uninfluential factor in happiness or that people are equally as generous regardless of happiness level. 

```{r}
qplot(Happy, Health, data=happy.s, geom="boxplot")
qplot(Happy, GDP, data=happy.s, geom="boxplot") 
qplot(Happy, Family, data=happy.s, geom="boxplot") 
qplot(Happy, Freedom, data=happy.s, geom="boxplot")
qplot(Happy, Trust, data=happy.s, geom="boxplot") #slight positive skew for unhappy
qplot(Happy, Generosity, data=happy.s, geom="boxplot") #slight positive skew for unhappy
```
*Data Mining Techniques*

*Logistic Regression*:

I begin my data mining analysis by fitting a General Linear Model on the regressor Happy. This is a logistic regression since the response variable is binary and my explanatory variables are continous. 
```{r}
happy.glm.scaled<-glm(Happy~., data=happy.s, family="binomial") # run logistic regression on Happy variable. I will use the scaled data so that it is easier to compare between units. 
#family= "binomial" indicates logit link function
summary(happy.glm.scaled)
pred.glm = predict(happy.glm.scaled, type="response") #use predict function to get our classifications from estimated probabilities (log odds)
pred.glm=round(pred.glm, digits=2) #round probabilities
Happiness = Happiness %>%
mutate(predHappy=as.factor(ifelse(pred.glm<=0.5, "0", "1"))) #predicted class labels from 
table(pred=Happiness$predHappy, true=Happiness$Happy) #Creating a confusion Matrix


pred.glm2 <- ifelse(pred.glm > 0.5,1,0)
MisClasErr <- mean(pred.glm2 != Happiness$Happy)
print(paste('Accuracy Rate:',1-MisClasErr))

```


From the output, it is important to note that GDP has the highest coefficient, followed by Family and then Health, meaning that their effects on predicted happiness are estimated to be the highest. I would also like to highlight the large p-value for Generosity, which indicates that it is not a significant variable in our model and can possibly be removed. At an alpha of 0.05, we would also find trust to be insignificant. 

Investigating the accuracy of this model:

Out of 157 cases (countries), our model classified 72+67= 139 correctly. This is 88.535% 
Out of the 79 "not happy" countries, the model classified 72 (91.139%) correctly. 
Out of 78 "happy" countries, the model classified 67 (85.897%) correctly. 

Accuracy Rate= (67+70) / (67+8+12+70) = 87.21%

False Positive Rate (FPR): 11/ 78 (14.10256%)
False Negative Rate (FNR): 7/ 79 ( 8.860759%)

The GLM model obtained an accuracy rate of 87.12%, which is fairly accurate. We are able to visualize the performace of the model with a ROC curve, which maps the True Positive Rate against the False Positive Rate. The high corresponding area under the curve (AUC) amount of .945, indicates that the GLM is an accurate model for the data. 

```{r}
pred = prediction(pred.glm, Happiness$Happy)
perf = performance(pred, measure="tpr", x.measure="fpr")
plot(perf, col=2, lwd=3, main="ROC curve")
abline(0,1)
auc = performance(pred, "auc")@y.values
#Calculate Area under the curve to evaluate performance of the glm model
auc
print(paste('AUC:',auc))
```

*Decision Tree*

Next, I decided to use a decision tree to model the data. To do this I regressed Happy on the explanatory variables using the scaled data as before and plugged that into tree function. I then plotted the tree and added the labels for each branch. 

```{r}
tree.happy = tree(Happy~., data = happy.s)
plot(tree.happy)
text(tree.happy, pretty = 0, cex = .8, col = "blue")
title("Classification Tree")
summary(tree.happy)
```

From the summary of the tree, we see that there are 12 nodes and that the model has a misclassification error rate of 0.05732. 

To test the accuracy of the model, I will create a training and test set by randomly partitioning the data. By fitting the model on the training data, I can then compare the model's predictions with the test data (which contains the true class labels). I follow the same process as before, but this time using the training set "trainSet". I then computed the test error rate and accuracy

```{r}
set.seed(1) #setting seed for random sample
trainSet = sample(1:nrow(happy.s), 0.75*dim(happy.s)[1]) #75% of observations set as training set
happy.test = happy.s [-trainSet,] #the remaining 25% of observations set as the test set
Happy.true = happy.test$Happy #true classifications of the test set

#Fit the tree on training set:
tree.training = tree(Happy~., data = happy.s, subset = trainSet)

plot(tree.training)
text(tree.training, pretty = 0, cex = .8, col = "red")
title("Classification Tree Built on Training Set")

summary(tree.training)

#Computing accuracy and test error rate:
TrainingTree.pred = predict(tree.training, happy.test, type="class")
TrainingTree.pred

error = table(TrainingTree.pred, Happy.true)
error
accuracy2=sum(diag(error))/sum(error) #Test accuracy rate
print(paste('Accuracy Rate:',accuracy2))
class_error=1-sum(diag(error))/sum(error) # Test error rate (Classification Error)
print(paste('Test error:',class_error))
```

The model produced an accuracy rate of 82.5%, which is lower than that of the GLM model. 

```{r}
set.seed(1)
cv = cv.tree(tree.training, FUN=prune.misclass) #10 fold cross validation (by default) to determine optimal tree complexity
summary(cv)
cv
best.cv = cv$size[which.min(cv$dev)]
best.cv
```

The optimal tree size, as determined by cross validation is 6 leaves. Therefore we will cut the tree, plot it, and extract the new confusion matrix and accuracy rate. 

```{r}
prune.cv = prune.misclass (tree.training, best=best.cv) #prune our decision tree built on the training set
plot(prune.cv)
text(prune.cv, pretty=0, col = "blue", cex = .8)
title("Pruned tree of size 6")
```

```{r}
pred.cv.prune = predict(prune.cv, happy.test, type="class") 
# confusion matrix
err.cv.prune = table(pred.cv.prune, Happy.true)
err.cv.prune
acc3=sum(diag(err.cv.prune))/sum(err.cv.prune)
1-sum(diag(err.cv.prune))/sum(err.cv.prune)
print(paste('Accuracy Rate:',acc3))
```

The pruned tree provides the same accuracy rate as our intital model but with less complexity, and is therefore preffered. However, the GLM model still remains the most accurate model for predicting happiness. 

*Conclusion*

The Logistic Regression model was able to predict the correct class label "Happy" with an accuracy rate of 87.21%. This was significantly higher than the accuracy rate of the decision tree (82.5%).  Additionally, from the GLM model and the initial exploratory analysis, I concluded that GPD per capita had the highest influence on happiness level while Generosity had the lowest. 




